diff --git a/crates/prism-core/src/auth/repository.rs b/crates/prism-core/src/auth/repository.rs
index a9eecdc..f5dd9fc 100644
--- a/crates/prism-core/src/auth/repository.rs
+++ b/crates/prism-core/src/auth/repository.rs
@@ -79,6 +79,14 @@ pub trait ApiKeyRepository: Send + Sync {
         api_key_id: i64,
         days: i64,
     ) -> Result<Vec<UsageStats>, AuthError>;
+
+    async fn update_name(&self, id: i64, name: &str) -> Result<(), AuthError>;
+
+    async fn update_allowed_methods(
+        &self,
+        id: i64,
+        methods: Option<Vec<String>>,
+    ) -> Result<(), AuthError>;
 }
 
 pub struct SqliteRepository {
@@ -463,6 +471,75 @@ impl ApiKeyRepository for SqliteRepository {
             })
             .collect()
     }
+
+    async fn update_name(&self, id: i64, name: &str) -> Result<(), AuthError> {
+        sqlx::query(
+            r"
+            UPDATE api_keys
+            SET name = ?, updated_at = CURRENT_TIMESTAMP
+            WHERE id = ?
+            ",
+        )
+        .bind(name)
+        .bind(id)
+        .execute(&self.pool)
+        .await?;
+
+        tracing::info!(key_id = id, new_name = name, "api key name updated");
+        Ok(())
+    }
+
+    async fn update_allowed_methods(
+        &self,
+        id: i64,
+        methods: Option<Vec<String>>,
+    ) -> Result<(), AuthError> {
+        let mut tx = self.pool.begin().await?;
+
+        // Delete existing method permissions
+        sqlx::query(
+            r"
+            DELETE FROM api_key_methods
+            WHERE api_key_id = ?
+            ",
+        )
+        .bind(id)
+        .execute(&mut *tx)
+        .await?;
+
+        // Insert new method permissions if provided
+        if let Some(method_list) = methods {
+            for method in method_list {
+                sqlx::query(
+                    r"
+                    INSERT INTO api_key_methods (api_key_id, method_name, max_requests_per_day)
+                    VALUES (?, ?, 1000)
+                    ",
+                )
+                .bind(id)
+                .bind(method)
+                .execute(&mut *tx)
+                .await?;
+            }
+        }
+
+        // Update the updated_at timestamp
+        sqlx::query(
+            r"
+            UPDATE api_keys
+            SET updated_at = CURRENT_TIMESTAMP
+            WHERE id = ?
+            ",
+        )
+        .bind(id)
+        .execute(&mut *tx)
+        .await?;
+
+        tx.commit().await?;
+
+        tracing::info!(key_id = id, "api key allowed methods updated");
+        Ok(())
+    }
 }
 
 #[cfg(test)]
diff --git a/crates/prism-core/src/cache/block_cache.rs b/crates/prism-core/src/cache/block_cache.rs
index fd44779..75ca32e 100644
--- a/crates/prism-core/src/cache/block_cache.rs
+++ b/crates/prism-core/src/cache/block_cache.rs
@@ -260,13 +260,18 @@ impl BlockCache {
         })
     }
 
-    /// Inserts a block header into both the hot window (if recent) and persistent storage.
+    /// Inserts a block header into both the hot window and persistent storage.
+    /// Note: Headers are inserted into hot window unconditionally. The hot window's
+    /// insert() method will automatically handle window positioning and ignore blocks
+    /// outside the valid range.
     pub async fn insert_header(&self, header: BlockHeader) {
         trace!(block = header.number, hash = ?header.hash, "inserting header");
 
         let header_arc = Arc::new(header);
 
-        if self.is_in_hot_window(header_arc.number) {
+        // Insert into hot window with empty body placeholder
+        // This allows the hot window to track recent blocks and auto-advance
+        {
             let block_number = header_arc.number;
             let hash = header_arc.hash;
             let empty_body = Arc::new(BlockBody { hash, transactions: vec![] });
@@ -292,14 +297,15 @@ impl BlockCache {
         let body_arc = Arc::new(body);
 
         if let Some(header_arc) = self.get_header_by_hash(&body_arc.hash) {
-            if self.is_in_hot_window(header_arc.number) {
-                let block_number = header_arc.number;
-                let body_clone = Arc::clone(&body_arc);
+            let block_number = header_arc.number;
+            let body_clone = Arc::clone(&body_arc);
 
-                let mut hot_window = self.hot_window.write().await;
-                if let Some(existing_header) = hot_window.get_header(block_number) {
-                    hot_window.insert(block_number, existing_header, body_clone);
-                }
+            let mut hot_window = self.hot_window.write().await;
+            if let Some(existing_header) = hot_window.get_header(block_number) {
+                hot_window.insert(block_number, existing_header, body_clone);
+            } else {
+                // Header exists in cache but not in hot window yet, insert both
+                hot_window.insert(block_number, header_arc, body_clone);
             }
         }
 
@@ -326,7 +332,6 @@ impl BlockCache {
 
         let hot_window_inserts: Vec<(u64, Arc<BlockHeader>, Arc<BlockBody>)> = header_arcs
             .iter()
-            .filter(|header_arc| self.is_in_hot_window(header_arc.number))
             .map(|header_arc| {
                 let empty_body =
                     Arc::new(BlockBody { hash: header_arc.hash, transactions: vec![] });
@@ -372,13 +377,8 @@ impl BlockCache {
         let hot_window_updates: Vec<(u64, Arc<BlockHeader>, Arc<BlockBody>)> = body_arcs
             .iter()
             .filter_map(|body_arc| {
-                self.get_header_by_hash(&body_arc.hash).and_then(|header_arc| {
-                    if self.is_in_hot_window(header_arc.number) {
-                        Some((header_arc.number, header_arc, Arc::clone(body_arc)))
-                    } else {
-                        None
-                    }
-                })
+                self.get_header_by_hash(&body_arc.hash)
+                    .map(|header_arc| (header_arc.number, header_arc, Arc::clone(body_arc)))
             })
             .collect();
 
@@ -480,10 +480,6 @@ impl BlockCache {
         }
     }
 
-    fn is_in_hot_window(&self, block_number: u64) -> bool {
-        self.hot_window.try_read().is_ok_and(|hw| hw.contains_block(block_number))
-    }
-
     /// Removes a block from all caches, typically called during chain reorganizations.
     pub async fn invalidate_block(&self, block_number: u64) {
         info!(block = block_number, "invalidating block");
@@ -567,8 +563,11 @@ impl BlockCache {
     }
 
     pub async fn get_stats(&self) -> CacheStats {
-        // Update stats if dirty flag is set
-        if self.stats_dirty.swap(false, std::sync::atomic::Ordering::Relaxed) {
+        // Fast path: check dirty flag with cheap load operation first
+        // Only use swap (expensive read-modify-write) if actually dirty
+        if self.stats_dirty.load(std::sync::atomic::Ordering::Relaxed) &&
+            self.stats_dirty.swap(false, std::sync::atomic::Ordering::Relaxed)
+        {
             self.compute_stats_internal().await;
         }
         self.stats.read().await.clone()
@@ -1280,9 +1279,8 @@ mod tests {
 
     #[tokio::test]
     async fn test_hot_window_stats() {
-        // Note: BlockCache's is_in_hot_window checks if block is already in hot window
-        // For stats, we verify header_cache_size and body_cache_size which reflect
-        // the DashMap contents, not the hot window circular buffer
+        // Verify that blocks are inserted into both hot window and DashMap caches
+        // header_cache_size and body_cache_size reflect DashMap contents
         let config = BlockCacheConfig { hot_window_size: 5, ..Default::default() };
         let cache = BlockCache::new(&config).expect("valid config");
 
@@ -1352,35 +1350,38 @@ mod tests {
         assert_eq!(cache.hit_count(), 1);
         assert_eq!(cache.miss_count(), 0);
 
-        // Miss: header exists but body is missing (orphaned header)
+        // Hit: header exists with empty body placeholder in hot window
+        // After the fix, insert_header now populates the hot window immediately
         let header_only = create_test_header(2000, 2);
         cache.insert_header(header_only).await;
         let result = cache.get_block_by_number(2000);
-        assert!(result.is_none());
-        assert_eq!(cache.hit_count(), 1);
-        assert_eq!(cache.miss_count(), 1);
+        assert!(result.is_some());
+        let (_, body) = result.unwrap();
+        assert_eq!(body.transactions.len(), 0, "Should have empty body placeholder");
+        assert_eq!(cache.hit_count(), 2);
+        assert_eq!(cache.miss_count(), 0);
 
         // Miss: header doesn't exist at all
         let result = cache.get_block_by_number(3000);
         assert!(result.is_none());
-        assert_eq!(cache.hit_count(), 1);
-        assert_eq!(cache.miss_count(), 2);
+        assert_eq!(cache.hit_count(), 2);
+        assert_eq!(cache.miss_count(), 1);
 
         // Another hit on the original block
         let result = cache.get_block_by_hash(&[1u8; 32]);
         assert!(result.is_some());
-        assert_eq!(cache.hit_count(), 2);
-        assert_eq!(cache.miss_count(), 2);
+        assert_eq!(cache.hit_count(), 3);
+        assert_eq!(cache.miss_count(), 1);
 
-        // Miss: header exists but body missing (by hash)
+        // Hit: header exists with empty body (by hash)
         let result = cache.get_block_by_hash(&[2u8; 32]);
-        assert!(result.is_none());
-        assert_eq!(cache.hit_count(), 2);
-        assert_eq!(cache.miss_count(), 3);
+        assert!(result.is_some());
+        assert_eq!(cache.hit_count(), 4);
+        assert_eq!(cache.miss_count(), 1);
 
         // Verify stats are updated correctly
         let stats = cache.get_stats().await;
-        assert_eq!(stats.block_cache_hits, 2);
-        assert_eq!(stats.block_cache_misses, 3);
+        assert_eq!(stats.block_cache_hits, 4);
+        assert_eq!(stats.block_cache_misses, 1);
     }
 }
diff --git a/crates/prism-core/src/cache/converter.rs b/crates/prism-core/src/cache/converter.rs
index 0bc5060..26b35c5 100644
--- a/crates/prism-core/src/cache/converter.rs
+++ b/crates/prism-core/src/cache/converter.rs
@@ -68,6 +68,36 @@ pub fn hex_to_u32(s: &str) -> Option<u32> {
     }
 }
 
+/// Parses variable-length hex string to a 32-byte big-endian array (uint256).
+/// Handles values like "0x0", "0xb59b9f7800", or full 32-byte hashes.
+/// The result is left-padded with zeros (big-endian format).
+#[must_use]
+pub fn hex_to_u256(hex: &str) -> Option<[u8; 32]> {
+    let hex_str = hex.strip_prefix("0x").unwrap_or(hex);
+
+    // Handle empty or too long values
+    if hex_str.is_empty() || hex_str.len() > 64 {
+        return None;
+    }
+
+    // Decode hex bytes
+    // Pad odd-length hex strings with leading zero
+    let padded_hex = if hex_str.len() % 2 == 1 {
+        format!("0{hex_str}")
+    } else {
+        hex_str.to_string()
+    };
+
+    let bytes = hex::decode(&padded_hex).ok()?;
+
+    // Left-pad to 32 bytes (big-endian)
+    let mut result = [0u8; 32];
+    let start = 32 - bytes.len();
+    result[start..].copy_from_slice(&bytes);
+
+    Some(result)
+}
+
 // --- Log Conversions ---
 
 /// Extracts log identifier from JSON-RPC log entry.
@@ -176,13 +206,31 @@ pub fn json_block_to_block_header(block: &Value) -> Option<BlockHeader> {
 }
 
 /// Extracts transaction hashes from JSON-RPC block to create `BlockBody`.
-/// Only works with blocks containing transaction hashes (not full tx objects).
+/// Handles both formats:
+/// - Transaction hashes as strings (when `fullTransactions=false`)
+/// - Full transaction objects (when `fullTransactions=true`) - extracts hash from each object
 #[must_use]
 pub fn json_block_to_block_body(block: &Value) -> Option<BlockBody> {
     let hash = hex_to_array::<32>(block.get("hash")?.as_str()?)?;
     let transactions = block.get("transactions")?.as_array()?;
-    let tx_hashes: Vec<_> =
-        transactions.iter().filter_map(|tx| hex_to_array::<32>(tx.as_str()?)).collect();
+    let tx_hashes: Vec<_> = transactions
+        .iter()
+        .filter_map(|tx| {
+            // Handle both formats: hash string or full transaction object
+            if let Some(hash_str) = tx.as_str() {
+                // Transaction is a string (hash only) - fullTransactions=false
+                hex_to_array::<32>(hash_str)
+            } else if let Some(tx_obj) = tx.as_object() {
+                // Transaction is an object (full tx) - fullTransactions=true
+                tx_obj
+                    .get("hash")
+                    .and_then(|h| h.as_str())
+                    .and_then(hex_to_array::<32>)
+            } else {
+                None
+            }
+        })
+        .collect();
     Some(BlockBody { hash, transactions: tx_hashes })
 }
 
@@ -266,28 +314,72 @@ pub fn block_header_and_body_to_json(header: &BlockHeader, body: &BlockBody) ->
 
 /// Converts JSON-RPC transaction to internal format.
 /// Handles optional fields (null for pending transactions).
+/// Supports all transaction types:
+/// - Legacy (type 0x0): uses `gasPrice`
+/// - EIP-2930 (type 0x1): uses `gasPrice` + `accessList`
+/// - EIP-1559 (type 0x2): uses `maxFeePerGas` + `maxPriorityFeePerGas` (no `gasPrice`)
+/// - EIP-4844 (type 0x3): uses `maxFeePerGas` + `maxPriorityFeePerGas` + `maxFeePerBlobGas`
 pub fn json_transaction_to_transaction_record(tx: &Value) -> Option<TransactionRecord> {
-    let hash = hex_to_array::<32>(tx.get("hash")?.as_str()?)?;
+    // Helper macro to log missing/invalid fields
+    macro_rules! require_field {
+        ($field:expr, $parser:expr) => {
+            match $parser {
+                Some(v) => v,
+                None => {
+                    tracing::warn!(
+                        field = $field,
+                        tx_hash = ?tx.get("hash").and_then(|v| v.as_str()),
+                        raw_value = ?tx.get($field),
+                        "transaction conversion failed: missing or invalid field"
+                    );
+                    return None;
+                }
+            }
+        };
+    }
+
+    let hash = require_field!("hash", tx.get("hash").and_then(|v| v.as_str()).and_then(hex_to_array::<32>));
     let block_hash = tx.get("blockHash").and_then(|v| v.as_str()).and_then(hex_to_array::<32>);
     let block_number = tx.get("blockNumber").and_then(|v| v.as_str()).and_then(hex_to_u64);
     let transaction_index =
         tx.get("transactionIndex").and_then(|v| v.as_str()).and_then(hex_to_u32);
-    let from = hex_to_array::<20>(tx.get("from")?.as_str()?)?;
+    let from = require_field!("from", tx.get("from").and_then(|v| v.as_str()).and_then(hex_to_array::<20>));
     let to = tx.get("to").and_then(|v| v.as_str()).and_then(hex_to_array::<20>);
-    let value = hex_to_array::<32>(tx.get("value")?.as_str()?)?;
-    let gas_price = hex_to_array::<32>(tx.get("gasPrice")?.as_str()?)?;
-    let gas_limit = hex_to_u64(tx.get("gas")?.as_str()?)?;
-    let nonce = hex_to_u64(tx.get("nonce")?.as_str()?)?;
-    let data = hex_to_bytes(tx.get("input")?.as_str()?)?;
+    // Value is variable-length hex (e.g., "0x0", "0xb59b9f7800"), needs padding to 32 bytes
+    let value = require_field!("value", tx.get("value").and_then(|v| v.as_str()).and_then(hex_to_u256));
 
-    // v is u8: parse as hex with 0x prefix, otherwise decimal
-    let v_str = tx.get("v")?.as_str()?;
-    let v = v_str
-        .strip_prefix("0x")
-        .map_or_else(|| v_str.parse::<u8>().ok(), |hex| u8::from_str_radix(hex, 16).ok())?;
+    // EIP-2718 tx types (0-255): 0=Legacy, 1=EIP-2930, 2=EIP-1559, 3=EIP-4844
+    #[allow(clippy::cast_possible_truncation)]
+    let tx_type = tx.get("type").and_then(|v| v.as_str()).and_then(hex_to_u64).and_then(|v| {
+        if v <= 255 {
+            Some(v as u8)
+        } else {
+            tracing::warn!(tx_type = v, "Invalid transaction type exceeds u8 range");
+            None
+        }
+    });
+
+    // Parse gas pricing fields - all are variable-length hex values
+    let gas_price = tx.get("gasPrice").and_then(|v| v.as_str()).and_then(hex_to_u256);
+    let max_fee_per_gas =
+        tx.get("maxFeePerGas").and_then(|v| v.as_str()).and_then(hex_to_u256);
+    let max_priority_fee_per_gas = tx
+        .get("maxPriorityFeePerGas")
+        .and_then(|v| v.as_str())
+        .and_then(hex_to_u256);
+    let max_fee_per_blob_gas =
+        tx.get("maxFeePerBlobGas").and_then(|v| v.as_str()).and_then(hex_to_u256);
 
-    let r = hex_to_array::<32>(tx.get("r")?.as_str()?)?;
-    let s = hex_to_array::<32>(tx.get("s")?.as_str()?)?;
+    let gas_limit = require_field!("gas", tx.get("gas").and_then(|v| v.as_str()).and_then(hex_to_u64));
+    let nonce = require_field!("nonce", tx.get("nonce").and_then(|v| v.as_str()).and_then(hex_to_u64));
+    let data = require_field!("input", tx.get("input").and_then(|v| v.as_str()).and_then(hex_to_bytes));
+
+    // v is u64: can be large for EIP-155 legacy transactions (chainId * 2 + 35/36)
+    let v = require_field!("v", tx.get("v").and_then(|v| v.as_str()).and_then(hex_to_u64));
+
+    // r and s are ECDSA signature components - can be <32 bytes if they have leading zeros
+    let r = require_field!("r", tx.get("r").and_then(|v| v.as_str()).and_then(hex_to_u256));
+    let s = require_field!("s", tx.get("s").and_then(|v| v.as_str()).and_then(hex_to_u256));
 
     Some(TransactionRecord {
         hash,
@@ -297,7 +389,11 @@ pub fn json_transaction_to_transaction_record(tx: &Value) -> Option<TransactionR
         from,
         to,
         value,
+        tx_type,
         gas_price,
+        max_fee_per_gas,
+        max_priority_fee_per_gas,
+        max_fee_per_blob_gas,
         gas_limit,
         nonce,
         data,
@@ -310,6 +406,7 @@ pub fn json_transaction_to_transaction_record(tx: &Value) -> Option<TransactionR
 /// Converts cached transaction back to JSON-RPC format.
 ///
 /// Uses optimized hex formatting (`format_hex_large`) for large input data (>256 bytes).
+/// Properly handles all transaction types by serializing the appropriate gas pricing fields.
 #[must_use]
 pub fn transaction_record_to_json(transaction: &TransactionRecord) -> Value {
     let mut tx = serde_json::Map::new();
@@ -346,7 +443,32 @@ pub fn transaction_record_to_json(transaction: &TransactionRecord) -> Value {
     }
 
     tx.insert("value".to_string(), Value::String(format_hash32(&transaction.value)));
-    tx.insert("gasPrice".to_string(), Value::String(format_hash32(&transaction.gas_price)));
+
+    // Include transaction type if present
+    if let Some(tx_type) = transaction.tx_type {
+        tx.insert("type".to_string(), Value::String(format_hex_u64(u64::from(tx_type))));
+    }
+
+    // Serialize gas pricing fields based on what's available
+    if let Some(gas_price) = transaction.gas_price {
+        tx.insert("gasPrice".to_string(), Value::String(format_hash32(&gas_price)));
+    }
+    if let Some(max_fee_per_gas) = transaction.max_fee_per_gas {
+        tx.insert("maxFeePerGas".to_string(), Value::String(format_hash32(&max_fee_per_gas)));
+    }
+    if let Some(max_priority_fee_per_gas) = transaction.max_priority_fee_per_gas {
+        tx.insert(
+            "maxPriorityFeePerGas".to_string(),
+            Value::String(format_hash32(&max_priority_fee_per_gas)),
+        );
+    }
+    if let Some(max_fee_per_blob_gas) = transaction.max_fee_per_blob_gas {
+        tx.insert(
+            "maxFeePerBlobGas".to_string(),
+            Value::String(format_hash32(&max_fee_per_blob_gas)),
+        );
+    }
+
     tx.insert("gas".to_string(), Value::String(format_hex_u64(transaction.gas_limit)));
     tx.insert("nonce".to_string(), Value::String(format_hex_u64(transaction.nonce)));
 
@@ -359,7 +481,7 @@ pub fn transaction_record_to_json(transaction: &TransactionRecord) -> Value {
         }),
     );
 
-    tx.insert("v".to_string(), Value::String(format_hex_u64(u64::from(transaction.v))));
+    tx.insert("v".to_string(), Value::String(format_hex_u64(transaction.v)));
     tx.insert("r".to_string(), Value::String(format_hash32(&transaction.r)));
     tx.insert("s".to_string(), Value::String(format_hash32(&transaction.s)));
 
@@ -563,6 +685,264 @@ mod tests {
         assert_eq!(hex_to_array::<3>("0x123456").expect("hex_to_array failed"), [0x12, 0x34, 0x56]);
     }
 
+    #[test]
+    fn test_hex_to_u256() {
+        // Zero value
+        let zero = hex_to_u256("0x0").unwrap();
+        assert_eq!(zero, [0u8; 32]);
+
+        // Small value (5 bytes) - should be left-padded
+        let small = hex_to_u256("0xb59b9f7800").unwrap();
+        let mut expected = [0u8; 32];
+        expected[27..32].copy_from_slice(&[0xb5, 0x9b, 0x9f, 0x78, 0x00]);
+        assert_eq!(small, expected);
+
+        // Odd-length hex (should pad with leading zero)
+        let odd = hex_to_u256("0x123").unwrap();
+        let mut expected_odd = [0u8; 32];
+        expected_odd[30..32].copy_from_slice(&[0x01, 0x23]);
+        assert_eq!(odd, expected_odd);
+
+        // Full 32-byte value
+        let full = hex_to_u256("0x0000000000000000000000000000000000000000000000000000000000000001").unwrap();
+        let mut expected_full = [0u8; 32];
+        expected_full[31] = 1;
+        assert_eq!(full, expected_full);
+
+        // Too long should fail
+        assert!(hex_to_u256("0x00000000000000000000000000000000000000000000000000000000000000001").is_none());
+
+        // Empty should fail
+        assert!(hex_to_u256("0x").is_none());
+    }
+
+    #[test]
+    fn test_hex_to_u256_leading_zeros() {
+        // Test that values with leading zeros stripped are correctly padded
+        // These are real examples from geth where leading zero bytes are stripped
+
+        // r value with 63 hex chars (missing one leading zero nibble)
+        // "0xd75..." should become "0x0d75..." when padded
+        let r_stripped = "0xd7536a2cecb99c6b785769e345b6be4e112a336209e15acd8ff4643d7521cd4";
+        assert_eq!(r_stripped.len(), 65); // 0x + 63 chars
+        let r_padded = hex_to_u256(r_stripped).unwrap();
+        // First byte should be 0x0d (the 'd' with leading zero)
+        assert_eq!(r_padded[0], 0x0d, "First byte should have leading zero restored");
+        assert_eq!(r_padded[1], 0x75, "Second byte should be 0x75");
+
+        // s value with 62 hex chars (missing two leading zero nibbles = one full byte)
+        let s_very_stripped = "0xeefaab9fb3d5330cddd143653ed4a2cce73c4367d7f9ed879f9682e579b2e8";
+        assert_eq!(s_very_stripped.len(), 64); // 0x + 62 chars
+        let s_padded = hex_to_u256(s_very_stripped).unwrap();
+        // First byte should be 0x00 (full byte of leading zeros)
+        assert_eq!(s_padded[0], 0x00, "First byte should be zero");
+        assert_eq!(s_padded[1], 0xee, "Second byte should be 0xee");
+
+        // Minimal value: "0x1" -> should be all zeros except last byte
+        let minimal = hex_to_u256("0x1").unwrap();
+        for i in 0..31 {
+            assert_eq!(minimal[i], 0x00, "Byte {i} should be zero for minimal value");
+        }
+        assert_eq!(minimal[31], 0x01, "Last byte should be 0x01");
+
+        // Verify numeric equivalence: padded and unpadded represent same value
+        let full_r = "0x0d7536a2cecb99c6b785769e345b6be4e112a336209e15acd8ff4643d7521cd4";
+        let full_r_parsed = hex_to_u256(full_r).unwrap();
+        assert_eq!(r_padded, full_r_parsed, "Stripped and full r should be equal");
+    }
+
+    #[test]
+    fn test_transaction_roundtrip_legacy() {
+        // Legacy transaction with compact hex values (as returned by geth)
+        let original_json = serde_json::json!({
+            "hash": "0xe36d216b68600a17795301c19c499641f61ac0c088121bb4c7d5b9ff2ed76021",
+            "blockHash": "0xabababababababababababababababababababababababababababababababab",
+            "blockNumber": "0x1234",
+            "transactionIndex": "0x5",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0xb59b9f7800",  // Compact: 5 bytes, not 32
+            "gas": "0x5208",
+            "gasPrice": "0x3b9aca00",  // Compact gas price
+            "nonce": "0x42",
+            "input": "0x",
+            "type": "0x0",
+            "v": "0x1c",  // Legacy v value (28)
+            "r": "0xd7536a2cecb99c6b785769e345b6be4e112a336209e15acd8ff4643d7521cd4",  // 63 hex chars!
+            "s": "0x1d2e640e84f58097604a89a3def961d10e6da51e1acda42a8ebb104512ca13a"   // 63 hex chars!
+        });
+
+        // Parse to TransactionRecord
+        let record = json_transaction_to_transaction_record(&original_json)
+            .expect("Failed to parse transaction");
+
+        // Convert back to JSON
+        let result_json = transaction_record_to_json(&record);
+
+        // Verify critical fields match (values should be equivalent, format may differ)
+        assert_eq!(
+            result_json.get("hash").unwrap().as_str().unwrap().to_lowercase(),
+            original_json.get("hash").unwrap().as_str().unwrap().to_lowercase()
+        );
+        assert_eq!(
+            result_json.get("from").unwrap().as_str().unwrap().to_lowercase(),
+            original_json.get("from").unwrap().as_str().unwrap().to_lowercase()
+        );
+        assert_eq!(
+            result_json.get("to").unwrap().as_str().unwrap().to_lowercase(),
+            original_json.get("to").unwrap().as_str().unwrap().to_lowercase()
+        );
+
+        // Value: original is compact, result may be padded - verify numeric equivalence
+        let orig_value = hex_to_u256(original_json.get("value").unwrap().as_str().unwrap()).unwrap();
+        let result_value = hex_to_u256(result_json.get("value").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_value, result_value, "value mismatch");
+
+        // Gas price
+        let orig_gas_price = hex_to_u256(original_json.get("gasPrice").unwrap().as_str().unwrap()).unwrap();
+        let result_gas_price = hex_to_u256(result_json.get("gasPrice").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_gas_price, result_gas_price, "gasPrice mismatch");
+
+        // r and s (signature components with stripped leading zeros)
+        let orig_r = hex_to_u256(original_json.get("r").unwrap().as_str().unwrap()).unwrap();
+        let result_r = hex_to_u256(result_json.get("r").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_r, result_r, "r signature mismatch");
+
+        let orig_s = hex_to_u256(original_json.get("s").unwrap().as_str().unwrap()).unwrap();
+        let result_s = hex_to_u256(result_json.get("s").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_s, result_s, "s signature mismatch");
+
+        // v value
+        let orig_v = hex_to_u64(original_json.get("v").unwrap().as_str().unwrap()).unwrap();
+        let result_v = hex_to_u64(result_json.get("v").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_v, result_v, "v mismatch");
+    }
+
+    #[test]
+    fn test_transaction_roundtrip_eip1559() {
+        // EIP-1559 transaction (type 2) with compact hex values
+        let original_json = serde_json::json!({
+            "hash": "0x1234567890123456789012345678901234567890123456789012345678901234",
+            "blockHash": "0xabababababababababababababababababababababababababababababababab",
+            "blockNumber": "0xabc",
+            "transactionIndex": "0x0",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0",  // Zero value transfer
+            "gas": "0x5208",
+            "maxFeePerGas": "0x59682f00",
+            "maxPriorityFeePerGas": "0x3b9aca00",
+            "nonce": "0x1",
+            "input": "0x1234",
+            "type": "0x2",
+            "v": "0x1",  // EIP-1559: just parity (0 or 1)
+            "r": "0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff",
+            "s": "0x1"  // Very small s value (1 byte after stripping)
+        });
+
+        let record = json_transaction_to_transaction_record(&original_json)
+            .expect("Failed to parse EIP-1559 transaction");
+
+        let result_json = transaction_record_to_json(&record);
+
+        // Verify type
+        assert_eq!(
+            hex_to_u64(result_json.get("type").unwrap().as_str().unwrap()).unwrap(),
+            2,
+            "type should be 2 for EIP-1559"
+        );
+
+        // Verify EIP-1559 gas fields
+        let orig_max_fee = hex_to_u256(original_json.get("maxFeePerGas").unwrap().as_str().unwrap()).unwrap();
+        let result_max_fee = hex_to_u256(result_json.get("maxFeePerGas").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_max_fee, result_max_fee, "maxFeePerGas mismatch");
+
+        let orig_priority = hex_to_u256(original_json.get("maxPriorityFeePerGas").unwrap().as_str().unwrap()).unwrap();
+        let result_priority = hex_to_u256(result_json.get("maxPriorityFeePerGas").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_priority, result_priority, "maxPriorityFeePerGas mismatch");
+
+        // Verify s with minimal value
+        let orig_s = hex_to_u256(original_json.get("s").unwrap().as_str().unwrap()).unwrap();
+        let result_s = hex_to_u256(result_json.get("s").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_s, result_s, "s signature mismatch for minimal value");
+
+        // EIP-1559 should NOT have gasPrice in output
+        assert!(result_json.get("gasPrice").is_none(), "EIP-1559 should not have gasPrice");
+    }
+
+    #[test]
+    fn test_transaction_roundtrip_eip155_high_chainid() {
+        // EIP-155 legacy transaction on a chain with high chainId (like devnet 1337)
+        // v = chainId * 2 + 35 = 1337 * 2 + 35 = 2709 = 0xa95
+        let original_json = serde_json::json!({
+            "hash": "0x5555555555555555555555555555555555555555555555555555555555555555",
+            "blockHash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockNumber": "0x100",
+            "transactionIndex": "0x0",
+            "from": "0x1111111111111111111111111111111111111111",
+            "to": "0x2222222222222222222222222222222222222222",
+            "value": "0xde0b6b3a7640000",  // 1 ETH in wei
+            "gas": "0x5208",
+            "gasPrice": "0x4a817c800",
+            "nonce": "0x0",
+            "input": "0x",
+            "type": "0x0",
+            "v": "0xa95",  // 2709 decimal - doesn't fit in u8!
+            "r": "0x1234567890123456789012345678901234567890123456789012345678901234",
+            "s": "0xabcdef0123456789abcdef0123456789abcdef0123456789abcdef0123456789"
+        });
+
+        let record = json_transaction_to_transaction_record(&original_json)
+            .expect("Failed to parse high chainId transaction");
+
+        // Verify v is stored correctly as u64
+        assert_eq!(record.v, 2709, "v should be 2709 for chainId 1337");
+
+        let result_json = transaction_record_to_json(&record);
+
+        let result_v = hex_to_u64(result_json.get("v").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(result_v, 2709, "v roundtrip failed for high chainId");
+    }
+
+    #[test]
+    fn test_transaction_roundtrip_contract_creation() {
+        // Contract creation transaction (to is null)
+        let original_json = serde_json::json!({
+            "hash": "0x9999999999999999999999999999999999999999999999999999999999999999",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x50",
+            "transactionIndex": "0x3",
+            "from": "0x3333333333333333333333333333333333333333",
+            "to": null,  // Contract creation!
+            "value": "0x0",
+            "gas": "0x100000",
+            "gasPrice": "0x3b9aca00",
+            "nonce": "0x5",
+            "input": "0x608060405234801561001057600080fd5b50",  // Contract bytecode
+            "type": "0x0",
+            "v": "0x1b",
+            "r": "0x1234567890123456789012345678901234567890123456789012345678901234",
+            "s": "0x1234567890123456789012345678901234567890123456789012345678901234"
+        });
+
+        let record = json_transaction_to_transaction_record(&original_json)
+            .expect("Failed to parse contract creation transaction");
+
+        assert!(record.to.is_none(), "to should be None for contract creation");
+
+        let result_json = transaction_record_to_json(&record);
+
+        assert!(
+            result_json.get("to").unwrap().is_null(),
+            "to should be null in JSON for contract creation"
+        );
+
+        // Verify input data preserved
+        let orig_input = hex_to_bytes(original_json.get("input").unwrap().as_str().unwrap()).unwrap();
+        let result_input = hex_to_bytes(result_json.get("input").unwrap().as_str().unwrap()).unwrap();
+        assert_eq!(orig_input, result_input, "input bytecode mismatch");
+    }
+
     #[test]
     fn test_log_conversion() {
         let json_log = serde_json::json!({
@@ -697,7 +1077,11 @@ mod tests {
             from: [0xCC; 20],
             to: Some([0xDD; 20]),
             value: [0xEE; 32],
-            gas_price: [0xFF; 32],
+            tx_type: Some(0),
+            gas_price: Some([0xFF; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 42,
             data: vec![0x11; 100],
@@ -960,7 +1344,7 @@ mod tests {
 
     #[test]
     fn test_json_block_to_block_body_with_full_tx_objects() {
-        // When transactions are full objects (not hashes), they should be skipped
+        // When transactions are full objects (not hashes), extract hash from object
         let block = serde_json::json!({
             "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
             "transactions": [
@@ -970,8 +1354,8 @@ mod tests {
         });
         let body = json_block_to_block_body(&block);
         assert!(body.is_some());
-        // Full tx object is skipped (as_str returns None)
-        assert_eq!(body.unwrap().transactions.len(), 1);
+        // Both transaction hashes are extracted (from object and string)
+        assert_eq!(body.unwrap().transactions.len(), 2);
     }
 
     #[test]
@@ -1205,9 +1589,150 @@ mod tests {
         assert!(json_transaction_to_transaction_record(&tx).is_none());
     }
 
+    #[test]
+    fn test_json_transaction_to_transaction_record_eip1559_with_max_fee() {
+        // EIP-1559 transaction has maxFeePerGas and maxPriorityFeePerGas, no gasPrice
+        let tx = serde_json::json!({
+            "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x3e8",
+            "transactionIndex": "0x5",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0000000000000000000000000000000000000000000000000de0b6b3a7640000",
+            "maxFeePerGas": "0x0000000000000000000000000000000000000000000000000000000077359400",
+            "maxPriorityFeePerGas": "0x0000000000000000000000000000000000000000000000000000000059682f00",
+            "gas": "0x5208",
+            "nonce": "0x2a",
+            "input": "0x",
+            "v": "0x1",
+            "r": "0x1111111111111111111111111111111111111111111111111111111111111111",
+            "s": "0x2222222222222222222222222222222222222222222222222222222222222222",
+            "type": "0x2"
+        });
+
+        let record = json_transaction_to_transaction_record(&tx);
+        assert!(record.is_some());
+        let record = record.unwrap();
+
+        assert_eq!(record.hash, [0xAA; 32]);
+        assert_eq!(record.block_number, Some(1000));
+        assert_eq!(record.tx_type, Some(2));
+        // EIP-1559 transaction should not have gasPrice
+        assert!(record.gas_price.is_none());
+        // Should have maxFeePerGas
+        assert!(record.max_fee_per_gas.is_some());
+        assert_eq!(record.max_fee_per_gas.unwrap()[31], 0x00);
+        assert_eq!(record.max_fee_per_gas.unwrap()[30], 0x94);
+        assert_eq!(record.gas_limit, 21000);
+    }
+
+    #[test]
+    fn test_json_transaction_to_transaction_record_eip4844_blob_tx() {
+        // EIP-4844 blob transaction with maxFeePerBlobGas
+        let tx = serde_json::json!({
+            "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x100",
+            "transactionIndex": "0x0",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0000000000000000000000000000000000000000000000000000000000000000",
+            "maxFeePerGas": "0x0000000000000000000000000000000000000000000000000000000077359400",
+            "maxPriorityFeePerGas": "0x0000000000000000000000000000000000000000000000000000000059682f00",
+            "maxFeePerBlobGas": "0x0000000000000000000000000000000000000000000000000000000000000001",
+            "gas": "0x5208",
+            "nonce": "0x0",
+            "input": "0x",
+            "v": "0x1",
+            "r": "0x1111111111111111111111111111111111111111111111111111111111111111",
+            "s": "0x2222222222222222222222222222222222222222222222222222222222222222",
+            "type": "0x3"
+        });
+
+        let record = json_transaction_to_transaction_record(&tx);
+        assert!(record.is_some());
+        let record = record.unwrap();
+
+        assert_eq!(record.hash, [0xAA; 32]);
+        assert_eq!(record.tx_type, Some(3));
+        // EIP-4844 transaction should not have gasPrice
+        assert!(record.gas_price.is_none());
+        // Should have maxFeePerGas
+        assert!(record.max_fee_per_gas.is_some());
+        assert_eq!(record.max_fee_per_gas.unwrap()[31], 0x00);
+        assert_eq!(record.max_fee_per_gas.unwrap()[30], 0x94);
+        // Should have maxFeePerBlobGas
+        assert!(record.max_fee_per_blob_gas.is_some());
+        assert_eq!(record.max_fee_per_blob_gas.unwrap()[31], 0x01);
+    }
+
+    #[test]
+    fn test_json_transaction_to_transaction_record_legacy_prefers_gas_price() {
+        // Legacy transaction with both gasPrice and maxFeePerGas (should prefer gasPrice)
+        let tx = serde_json::json!({
+            "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x3e8",
+            "transactionIndex": "0x5",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0000000000000000000000000000000000000000000000000de0b6b3a7640000",
+            "gasPrice": "0x0000000000000000000000000000000000000000000000000000000012345678",
+            "maxFeePerGas": "0x0000000000000000000000000000000000000000000000000000000077359400",
+            "gas": "0x5208",
+            "nonce": "0x2a",
+            "input": "0x",
+            "v": "0x1b",
+            "r": "0x1111111111111111111111111111111111111111111111111111111111111111",
+            "s": "0x2222222222222222222222222222222222222222222222222222222222222222"
+        });
+
+        let record = json_transaction_to_transaction_record(&tx);
+        assert!(record.is_some());
+        let record = record.unwrap();
+
+        // Should have gasPrice
+        assert!(record.gas_price.is_some());
+        let gas_price = record.gas_price.unwrap();
+        assert_eq!(gas_price[31], 0x78);
+        assert_eq!(gas_price[30], 0x56);
+        assert_eq!(gas_price[29], 0x34);
+        assert_eq!(gas_price[28], 0x12);
+        // Should also have maxFeePerGas (both can be present)
+        assert!(record.max_fee_per_gas.is_some());
+    }
+
+    #[test]
+    fn test_json_transaction_to_transaction_record_missing_both_gas_prices() {
+        // Transaction missing both gasPrice and maxFeePerGas should now succeed (both are optional)
+        let tx = serde_json::json!({
+            "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x3e8",
+            "transactionIndex": "0x5",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0000000000000000000000000000000000000000000000000de0b6b3a7640000",
+            "gas": "0x5208",
+            "nonce": "0x2a",
+            "input": "0x",
+            "v": "0x1b",
+            "r": "0x1111111111111111111111111111111111111111111111111111111111111111",
+            "s": "0x2222222222222222222222222222222222222222222222222222222222222222"
+        });
+
+        let record = json_transaction_to_transaction_record(&tx);
+        assert!(record.is_some());
+        let record = record.unwrap();
+        // Both should be None
+        assert!(record.gas_price.is_none());
+        assert!(record.max_fee_per_gas.is_none());
+    }
+
     #[test]
     fn test_transaction_record_to_json_null_fields() {
-        // Test null field serialization (lines 424, 430, 439, 447)
+        // Test null field serialization
         let transaction = TransactionRecord {
             hash: [0xAA; 32],
             block_hash: None,
@@ -1216,7 +1741,11 @@ mod tests {
             from: [0xCC; 20],
             to: None,
             value: [0; 32],
-            gas_price: [0; 32],
+            tx_type: Some(0),
+            gas_price: Some([0; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 0,
             data: vec![],
@@ -1235,7 +1764,7 @@ mod tests {
 
     #[test]
     fn test_transaction_record_to_json_large_input_data() {
-        // Test format_hex_large path for data > 256 bytes (lines 457-461)
+        // Test format_hex_large path for data > 256 bytes
         let transaction = TransactionRecord {
             hash: [0xAA; 32],
             block_hash: Some([0xBB; 32]),
@@ -1244,7 +1773,11 @@ mod tests {
             from: [0xCC; 20],
             to: Some([0xDD; 20]),
             value: [0; 32],
-            gas_price: [0; 32],
+            tx_type: Some(0),
+            gas_price: Some([0; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 500_000,
             nonce: 0,
             data: vec![0xAB; 500], // > 256 bytes triggers format_hex_large
@@ -1259,9 +1792,51 @@ mod tests {
         assert_eq!(input.len(), 2 + 500 * 2); // "0x" + 500 bytes * 2 hex chars
     }
 
+    #[test]
+    fn test_json_transaction_eip1559_roundtrip() {
+        // Test full roundtrip for EIP-1559 transaction
+        let original_json = serde_json::json!({
+            "hash": "0xaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
+            "blockHash": "0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb",
+            "blockNumber": "0x3e8",
+            "transactionIndex": "0x5",
+            "from": "0x1234567890123456789012345678901234567890",
+            "to": "0xabcdefabcdefabcdefabcdefabcdefabcdefabcd",
+            "value": "0x0000000000000000000000000000000000000000000000000de0b6b3a7640000",
+            "maxFeePerGas": "0x0000000000000000000000000000000000000000000000000000000077359400",
+            "maxPriorityFeePerGas": "0x0000000000000000000000000000000000000000000000000000000059682f00",
+            "gas": "0x5208",
+            "nonce": "0x2a",
+            "input": "0x",
+            "v": "0x1b",
+            "r": "0x1111111111111111111111111111111111111111111111111111111111111111",
+            "s": "0x2222222222222222222222222222222222222222222222222222222222222222",
+            "type": "0x2"
+        });
+
+        // Parse to record
+        let record = json_transaction_to_transaction_record(&original_json).unwrap();
+
+        // Verify fields are parsed correctly
+        assert_eq!(record.tx_type, Some(2));
+        assert!(record.gas_price.is_none());
+        assert!(record.max_fee_per_gas.is_some());
+        assert!(record.max_priority_fee_per_gas.is_some());
+        assert!(record.max_fee_per_blob_gas.is_none());
+
+        // Convert back to JSON
+        let json = transaction_record_to_json(&record);
+
+        // Verify critical fields are present
+        assert_eq!(json.get("type").unwrap().as_str().unwrap(), "0x2");
+        assert!(json.get("maxFeePerGas").is_some());
+        assert!(json.get("maxPriorityFeePerGas").is_some());
+        assert!(json.get("gasPrice").is_none());
+    }
+
     #[test]
     fn test_transaction_record_to_json_small_input_data() {
-        // Test format_hex path for data <= 256 bytes (line 460)
+        // Test format_hex path for data <= 256 bytes
         let transaction = TransactionRecord {
             hash: [0xAA; 32],
             block_hash: Some([0xBB; 32]),
@@ -1270,7 +1845,11 @@ mod tests {
             from: [0xCC; 20],
             to: Some([0xDD; 20]),
             value: [0; 32],
-            gas_price: [0; 32],
+            tx_type: Some(0),
+            gas_price: Some([0; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 100_000,
             nonce: 0,
             data: vec![0xAB; 100], // <= 256 bytes uses format_hex
diff --git a/crates/prism-core/src/cache/manager/tests/transaction_tests.rs b/crates/prism-core/src/cache/manager/tests/transaction_tests.rs
index aa8a980..0d979a1 100644
--- a/crates/prism-core/src/cache/manager/tests/transaction_tests.rs
+++ b/crates/prism-core/src/cache/manager/tests/transaction_tests.rs
@@ -42,7 +42,11 @@ async fn test_warm_transactions() {
         from: [0; 20],
         to: Some([1; 20]),
         value: [0; 32],
-        gas_price: [0; 32],
+        tx_type: Some(0), // Legacy transaction
+        gas_price: Some([0; 32]),
+        max_fee_per_gas: None,
+        max_priority_fee_per_gas: None,
+        max_fee_per_blob_gas: None,
         gas_limit: 21000,
         nonce: 0,
         data: vec![],
diff --git a/crates/prism-core/src/cache/transaction_cache.rs b/crates/prism-core/src/cache/transaction_cache.rs
index 6219e93..742d913 100644
--- a/crates/prism-core/src/cache/transaction_cache.rs
+++ b/crates/prism-core/src/cache/transaction_cache.rs
@@ -364,9 +364,27 @@ impl TransactionCache {
             return;
         }
 
-        // Collect and sort block numbers (oldest first)
+        // Collect block numbers - use partial sorting for efficiency
+        // Estimate: we need approximately to_evict / avg_txs_per_block blocks
+        // Use a minimum of 10 blocks as a starting estimate
         let mut blocks: Vec<u64> = self.block_transactions.iter().map(|e| *e.key()).collect();
-        blocks.sort_unstable();
+
+        if blocks.is_empty() {
+            return;
+        }
+
+        // Optimization: use select_nth_unstable for O(n) partial sorting
+        // instead of full O(n log n) sort when we only need oldest blocks
+        let estimated_blocks_needed = (to_evict / 10).max(10).min(blocks.len());
+        if estimated_blocks_needed < blocks.len() {
+            // Partition so that blocks[0..k] contains the k smallest block numbers
+            blocks.select_nth_unstable(estimated_blocks_needed.saturating_sub(1));
+            // Only sort the subset we'll actually use
+            blocks[..estimated_blocks_needed].sort_unstable();
+        } else {
+            // If we might need all blocks, just do a full sort
+            blocks.sort_unstable();
+        }
 
         let mut evicted = 0;
         for block in blocks {
@@ -442,7 +460,11 @@ mod tests {
             from: [3u8; 20],
             to: Some([4u8; 20]),
             value: [5u8; 32],
-            gas_price: [6u8; 32],
+            tx_type: Some(0), // Legacy transaction
+            gas_price: Some([6u8; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 0,
             data: vec![1, 2, 3],
@@ -504,7 +526,11 @@ mod tests {
             from: [3u8; 20],
             to: Some([4u8; 20]),
             value: [5u8; 32],
-            gas_price: [6u8; 32],
+            tx_type: Some(0), // Legacy transaction
+            gas_price: Some([6u8; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 0,
             data: vec![],
@@ -556,7 +582,11 @@ mod tests {
             from: [3u8; 20],
             to: Some([4u8; 20]),
             value: [5u8; 32],
-            gas_price: [6u8; 32],
+            tx_type: Some(0), // Legacy transaction
+            gas_price: Some([6u8; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 0,
             data: vec![],
@@ -587,7 +617,11 @@ mod tests {
             from: [1u8; 20],
             to: Some([2u8; 20]),
             value: [0u8; 32],
-            gas_price: [1u8; 32],
+            tx_type: Some(0), // Legacy transaction
+            gas_price: Some([1u8; 32]),
+            max_fee_per_gas: None,
+            max_priority_fee_per_gas: None,
+            max_fee_per_blob_gas: None,
             gas_limit: 21000,
             nonce: 0,
             data: vec![],
diff --git a/crates/prism-core/src/cache/types.rs b/crates/prism-core/src/cache/types.rs
index 7512e67..cb7a9a7 100644
--- a/crates/prism-core/src/cache/types.rs
+++ b/crates/prism-core/src/cache/types.rs
@@ -462,7 +462,7 @@ pub struct BlockBody {
     pub transactions: Vec<[u8; 32]>,
 }
 
-/// Transaction record
+/// Transaction record supporting all Ethereum transaction types
 #[derive(Debug, Clone, Serialize, Deserialize)]
 pub struct TransactionRecord {
     pub hash: [u8; 32],
@@ -472,11 +472,22 @@ pub struct TransactionRecord {
     pub from: [u8; 20],
     pub to: Option<[u8; 20]>,
     pub value: [u8; 32],
-    pub gas_price: [u8; 32],
+    /// Transaction type (0 = legacy, 1 = EIP-2930, 2 = EIP-1559, 3 = EIP-4844)
+    pub tx_type: Option<u8>,
+    /// Gas price for legacy/EIP-2930 transactions
+    pub gas_price: Option<[u8; 32]>,
+    /// Max fee per gas for EIP-1559/EIP-4844 transactions
+    pub max_fee_per_gas: Option<[u8; 32]>,
+    /// Max priority fee per gas for EIP-1559/EIP-4844 transactions
+    pub max_priority_fee_per_gas: Option<[u8; 32]>,
+    /// Max fee per blob gas for EIP-4844 transactions
+    pub max_fee_per_blob_gas: Option<[u8; 32]>,
     pub gas_limit: u64,
     pub nonce: u64,
     pub data: Vec<u8>,
-    pub v: u8,
+    /// Signature recovery id. For EIP-155 legacy transactions: chainId * 2 + 35/36.
+    /// For EIP-2930+ transactions: just the parity (0 or 1).
+    pub v: u64,
     pub r: [u8; 32],
     pub s: [u8; 32],
 }
diff --git a/crates/prism-core/src/config/mod.rs b/crates/prism-core/src/config/mod.rs
index 64eba95..de0eca2 100644
--- a/crates/prism-core/src/config/mod.rs
+++ b/crates/prism-core/src/config/mod.rs
@@ -45,6 +45,7 @@ use crate::{
 use config::{Config, ConfigError, Environment, File};
 use serde::{Deserialize, Serialize};
 use std::{path::Path, sync::Arc, time::Duration};
+use tracing::warn;
 
 /// HTTP server configuration settings.
 #[derive(Debug, Clone, Serialize, Deserialize)]
@@ -617,6 +618,29 @@ impl AppConfig {
             return Err("Logging format must be 'json' or 'pretty'".to_string());
         }
 
+        // Security warning: Admin API enabled without authentication
+        if self.admin.enabled && self.admin.admin_token.is_none() {
+            if self.environment != "development" && self.environment != "test" {
+                warn!(
+                    "SECURITY WARNING: Admin API is enabled without authentication! \
+                     Set PRISM_ADMIN__ADMIN_TOKEN environment variable to secure the admin API."
+                );
+            }
+        }
+
+        // Validate admin token is not empty if set
+        if let Some(ref token) = self.admin.admin_token {
+            if token.trim().is_empty() {
+                return Err("Admin token cannot be empty".to_string());
+            }
+            if token.len() < 16 {
+                warn!(
+                    "Admin token is shorter than recommended minimum of 16 characters. \
+                     Consider using a longer, more secure token."
+                );
+            }
+        }
+
         Ok(())
     }
 
diff --git a/crates/prism-core/src/middleware/auth.rs b/crates/prism-core/src/middleware/auth.rs
index 7ffcadf..828a488 100644
--- a/crates/prism-core/src/middleware/auth.rs
+++ b/crates/prism-core/src/middleware/auth.rs
@@ -228,6 +228,18 @@ mod tests {
         ) -> Result<Vec<crate::auth::repository::UsageStats>, AuthError> {
             Ok(Vec::new())
         }
+
+        async fn update_name(&self, _id: i64, _name: &str) -> Result<(), AuthError> {
+            Ok(())
+        }
+
+        async fn update_allowed_methods(
+            &self,
+            _id: i64,
+            _methods: Option<Vec<String>>,
+        ) -> Result<(), AuthError> {
+            Ok(())
+        }
     }
 
     fn create_test_api_key(id: i64, name: &str) -> ApiKey {
diff --git a/crates/prism-core/src/proxy/handlers/blocks.rs b/crates/prism-core/src/proxy/handlers/blocks.rs
index 283d0f9..3021af1 100644
--- a/crates/prism-core/src/proxy/handlers/blocks.rs
+++ b/crates/prism-core/src/proxy/handlers/blocks.rs
@@ -149,9 +149,15 @@ impl BlocksHandler {
     /// Validates block data integrity before caching to prevent cache poisoning.
     /// Converts JSON block data to header and body records, validates integrity,
     /// then stores them in cache only if validation passes.
+    ///
+    /// If the block contains full transaction objects (fullTransactions=true),
+    /// also extracts and caches individual transactions.
     async fn cache_block_from_response(&self, block_json: &serde_json::Value) {
         use crate::cache::{
-            converter::{json_block_to_block_body, json_block_to_block_header},
+            converter::{
+                json_block_to_block_body, json_block_to_block_header,
+                json_transaction_to_transaction_record,
+            },
             validation::validate_block_response,
         };
 
@@ -161,9 +167,40 @@ impl BlocksHandler {
         }
 
         if let Some(header) = json_block_to_block_header(block_json) {
+            let block_number = header.number;
+
             if let Some(body) = json_block_to_block_body(block_json) {
                 self.ctx.cache_manager.insert_header(header).await;
                 self.ctx.cache_manager.insert_body(body).await;
+
+                // Extract and cache individual transactions if present as objects
+                if let Some(transactions) = block_json.get("transactions").and_then(|v| v.as_array())
+                {
+                    // Check if transactions are full objects (not just hashes)
+                    if let Some(first_tx) = transactions.first() {
+                        if first_tx.is_object() {
+                            // Full transaction objects - cache them individually
+                            let mut cached_count = 0;
+                            for tx_json in transactions {
+                                if let Some(tx) = json_transaction_to_transaction_record(tx_json) {
+                                    self.ctx
+                                        .cache_manager
+                                        .transaction_cache
+                                        .insert_transaction(tx)
+                                        .await;
+                                    cached_count += 1;
+                                }
+                            }
+                            if cached_count > 0 {
+                                tracing::debug!(
+                                    block_number = block_number,
+                                    transaction_count = cached_count,
+                                    "cached transactions from block"
+                                );
+                            }
+                        }
+                    }
+                }
             } else {
                 tracing::warn!("failed to convert json block to block body, skipping body cache");
             }
diff --git a/crates/prism-core/src/upstream/builder.rs b/crates/prism-core/src/upstream/builder.rs
index 61a7116..c7ed103 100644
--- a/crates/prism-core/src/upstream/builder.rs
+++ b/crates/prism-core/src/upstream/builder.rs
@@ -2,12 +2,12 @@
 
 use super::{
     consensus::{ConsensusConfig, ConsensusEngine},
+    dynamic_registry::DynamicUpstreamRegistry,
     hedging::{HedgeConfig, HedgeExecutor},
     http_client::HttpClient,
     load_balancer::LoadBalancer,
     manager::{UpstreamManager, UpstreamManagerConfig},
     router::{RoutingContext, SmartRouter},
-    runtime_registry::RuntimeUpstreamRegistry,
     scoring::{ScoringConfig, ScoringEngine},
 };
 use crate::chain::ChainState;
@@ -57,7 +57,7 @@ pub struct UpstreamManagerBuilder {
     hedge_config: HedgeConfig,
     consensus_config: ConsensusConfig,
     router: Option<Arc<SmartRouter>>,
-    runtime_storage_path: Option<PathBuf>,
+    dynamic_storage_path: Option<PathBuf>,
 }
 
 impl UpstreamManagerBuilder {
@@ -72,7 +72,7 @@ impl UpstreamManagerBuilder {
             hedge_config: HedgeConfig::default(),
             consensus_config: ConsensusConfig::default(),
             router: None,
-            runtime_storage_path: None,
+            dynamic_storage_path: None,
         }
     }
 
@@ -138,12 +138,12 @@ impl UpstreamManagerBuilder {
         self
     }
 
-    /// Sets the storage path for runtime upstreams persistence.
+    /// Sets the storage path for dynamic upstreams persistence.
     ///
-    /// If set, runtime upstreams will be persisted to this file and loaded on restart.
+    /// If set, dynamic upstreams will be persisted to this file and loaded on restart.
     #[must_use]
-    pub fn runtime_storage_path(mut self, path: PathBuf) -> Self {
-        self.runtime_storage_path = Some(path);
+    pub fn dynamic_storage_path(mut self, path: PathBuf) -> Self {
+        self.dynamic_storage_path = Some(path);
         self
     }
 
@@ -167,8 +167,8 @@ impl UpstreamManagerBuilder {
         let scoring_engine = Arc::new(ScoringEngine::new(self.scoring_config, chain_state.clone()));
         let consensus_engine = Arc::new(ConsensusEngine::new(self.consensus_config));
 
-        // Create runtime upstream registry
-        let runtime_registry = Arc::new(RuntimeUpstreamRegistry::new(self.runtime_storage_path));
+        // Create dynamic upstream registry
+        let dynamic_registry = Arc::new(DynamicUpstreamRegistry::new(self.dynamic_storage_path));
 
         // Create routing context
         let routing_context = Arc::new(RoutingContext::new(
@@ -191,7 +191,7 @@ impl UpstreamManagerBuilder {
             consensus_engine,
             routing_context,
             router,
-            runtime_registry,
+            dynamic_registry,
         ))
     }
 }
diff --git a/crates/prism-core/src/upstream/runtime_registry.rs b/crates/prism-core/src/upstream/dynamic_registry.rs
similarity index 72%
rename from crates/prism-core/src/upstream/runtime_registry.rs
rename to crates/prism-core/src/upstream/dynamic_registry.rs
index 042aaf5..e5306cf 100644
--- a/crates/prism-core/src/upstream/runtime_registry.rs
+++ b/crates/prism-core/src/upstream/dynamic_registry.rs
@@ -1,7 +1,7 @@
-//! Runtime upstream registry for tracking runtime-added upstreams.
+//! Dynamic upstream registry for tracking dynamically-added upstreams.
 //!
 //! This module provides a registry to distinguish between upstreams loaded from config
-//! and those added via the admin API at runtime. Runtime upstreams are persisted to disk
+//! and those added via the admin API at runtime. Dynamic upstreams are persisted to disk
 //! for restart survival.
 
 use parking_lot::RwLock;
@@ -9,12 +9,12 @@ use serde::{Deserialize, Serialize};
 use std::{collections::HashMap, fs, path::PathBuf};
 use tracing::{debug, error, info};
 
-/// Configuration for a runtime-added upstream.
+/// Configuration for a dynamically-added upstream.
 ///
 /// This is persisted to disk and contains all information needed to reconstruct
 /// the upstream after a restart.
 #[derive(Debug, Clone, Serialize, Deserialize)]
-pub struct RuntimeUpstreamConfig {
+pub struct DynamicUpstreamConfig {
     pub id: String,
     pub name: String,
     pub url: String,
@@ -32,33 +32,33 @@ pub struct RuntimeUpstreamConfig {
 pub enum UpstreamSource {
     /// Loaded from TOML configuration file.
     Config,
-    /// Added via admin API at runtime.
-    Runtime,
+    /// Added via admin API at runtime (dynamic).
+    Dynamic,
 }
 
-/// Registry for tracking runtime-added upstreams.
+/// Registry for tracking dynamically-added upstreams.
 ///
-/// Maintains separation between config-based and runtime-added upstreams,
-/// providing persistence for runtime upstreams.
-pub struct RuntimeUpstreamRegistry {
-    /// Runtime-added upstreams indexed by ID.
-    runtime_upstreams: RwLock<HashMap<String, RuntimeUpstreamConfig>>,
+/// Maintains separation between config-based and dynamically-added upstreams,
+/// providing persistence for dynamic upstreams.
+pub struct DynamicUpstreamRegistry {
+    /// Dynamically-added upstreams indexed by ID.
+    dynamic_upstreams: RwLock<HashMap<String, DynamicUpstreamConfig>>,
     /// Names of upstreams from config (for source checking).
     config_upstream_names: RwLock<Vec<String>>,
     /// Optional file path for persistence.
     storage_path: Option<PathBuf>,
 }
 
-impl RuntimeUpstreamRegistry {
-    /// Creates a new runtime upstream registry.
+impl DynamicUpstreamRegistry {
+    /// Creates a new dynamic upstream registry.
     ///
     /// # Arguments
     ///
-    /// * `storage_path` - Optional path to JSON file for persisting runtime upstreams
+    /// * `storage_path` - Optional path to JSON file for persisting dynamic upstreams
     #[must_use]
     pub fn new(storage_path: Option<PathBuf>) -> Self {
         Self {
-            runtime_upstreams: RwLock::new(HashMap::new()),
+            dynamic_upstreams: RwLock::new(HashMap::new()),
             config_upstream_names: RwLock::new(Vec::new()),
             storage_path,
         }
@@ -73,29 +73,29 @@ impl RuntimeUpstreamRegistry {
         debug!(count = config_names.len(), "initialized config upstream names");
     }
 
-    /// Adds a runtime upstream to the registry.
+    /// Adds a dynamic upstream to the registry.
     ///
     /// # Errors
     ///
     /// Returns an error if:
     /// - An upstream with the same name already exists
-    /// - The upstream ID conflicts with an existing runtime upstream
+    /// - The upstream ID conflicts with an existing dynamic upstream
     /// - Persistence fails
-    pub fn add(&self, config: &RuntimeUpstreamConfig) -> Result<String, String> {
+    pub fn add(&self, config: &DynamicUpstreamConfig) -> Result<String, String> {
         // Check if name conflicts with config upstreams
         if self.is_config_upstream(&config.name) {
             return Err(format!(
-                "Cannot add runtime upstream '{}': name conflicts with config upstream",
+                "Cannot add dynamic upstream '{}': name conflicts with config upstream",
                 config.name
             ));
         }
 
-        // Check if name conflicts with existing runtime upstreams
+        // Check if name conflicts with existing dynamic upstreams
         {
-            let upstreams = self.runtime_upstreams.read();
+            let upstreams = self.dynamic_upstreams.read();
             if upstreams.values().any(|u| u.name == config.name) {
                 return Err(format!(
-                    "Cannot add runtime upstream '{}': name already exists",
+                    "Cannot add dynamic upstream '{}': name already exists",
                     config.name
                 ));
             }
@@ -105,21 +105,21 @@ impl RuntimeUpstreamRegistry {
 
         // Add to registry
         {
-            let mut upstreams = self.runtime_upstreams.write();
+            let mut upstreams = self.dynamic_upstreams.write();
             upstreams.insert(id.clone(), config.clone());
         }
 
         // Persist to disk
         if let Err(e) = self.save_to_disk() {
-            error!(error = %e, "failed to persist runtime upstreams");
+            error!(error = %e, "failed to persist dynamic upstreams");
             // Don't fail the operation, but log the error
         }
 
-        info!(id = %id, name = %config.name, "added runtime upstream");
+        info!(id = %id, name = %config.name, "added dynamic upstream");
         Ok(id)
     }
 
-    /// Updates a runtime upstream.
+    /// Updates a dynamic upstream.
     ///
     /// # Errors
     ///
@@ -127,16 +127,16 @@ impl RuntimeUpstreamRegistry {
     /// - The upstream ID doesn't exist
     /// - The new name conflicts with another upstream
     /// - Persistence fails
-    pub fn update(&self, id: &str, updates: RuntimeUpstreamUpdate) -> Result<(), String> {
+    pub fn update(&self, id: &str, updates: DynamicUpstreamUpdate) -> Result<(), String> {
         // Check for name conflicts first, before acquiring write lock
         if let Some(ref new_name) = updates.name {
-            let upstreams = self.runtime_upstreams.read();
+            let upstreams = self.dynamic_upstreams.read();
 
             // Get current name
             let current_name = upstreams
                 .get(id)
                 .map(|u| u.name.clone())
-                .ok_or_else(|| format!("Runtime upstream '{id}' not found"))?;
+                .ok_or_else(|| format!("Dynamic upstream '{id}' not found"))?;
 
             if new_name != &current_name {
                 // Check config upstreams
@@ -146,7 +146,7 @@ impl RuntimeUpstreamRegistry {
                     ));
                 }
 
-                // Check other runtime upstreams
+                // Check other dynamic upstreams
                 if upstreams.values().any(|u| u.id != id && &u.name == new_name) {
                     return Err(format!("Cannot rename to '{new_name}': name already exists"));
                 }
@@ -154,11 +154,11 @@ impl RuntimeUpstreamRegistry {
         }
 
         // Now acquire write lock and apply updates
-        let mut upstreams = self.runtime_upstreams.write();
+        let mut upstreams = self.dynamic_upstreams.write();
 
         let config = upstreams
             .get_mut(id)
-            .ok_or_else(|| format!("Runtime upstream '{id}' not found"))?;
+            .ok_or_else(|| format!("Dynamic upstream '{id}' not found"))?;
 
         // Apply updates
         if let Some(name) = updates.name {
@@ -184,47 +184,47 @@ impl RuntimeUpstreamRegistry {
 
         // Persist to disk
         if let Err(e) = self.save_to_disk() {
-            error!(error = %e, "failed to persist runtime upstreams");
+            error!(error = %e, "failed to persist dynamic upstreams");
         }
 
-        info!(id = %id, "updated runtime upstream");
+        info!(id = %id, "updated dynamic upstream");
         Ok(())
     }
 
-    /// Removes a runtime upstream from the registry.
+    /// Removes a dynamic upstream from the registry.
     ///
     /// # Errors
     ///
     /// Returns an error if the upstream ID doesn't exist.
-    pub fn remove(&self, id: &str) -> Result<RuntimeUpstreamConfig, String> {
-        let mut upstreams = self.runtime_upstreams.write();
+    pub fn remove(&self, id: &str) -> Result<DynamicUpstreamConfig, String> {
+        let mut upstreams = self.dynamic_upstreams.write();
 
         let config = upstreams
             .remove(id)
-            .ok_or_else(|| format!("Runtime upstream '{id}' not found"))?;
+            .ok_or_else(|| format!("Dynamic upstream '{id}' not found"))?;
 
         drop(upstreams);
 
         // Persist to disk
         if let Err(e) = self.save_to_disk() {
-            error!(error = %e, "failed to persist runtime upstreams");
+            error!(error = %e, "failed to persist dynamic upstreams");
         }
 
-        info!(id = %id, name = %config.name, "removed runtime upstream");
+        info!(id = %id, name = %config.name, "removed dynamic upstream");
         Ok(config)
     }
 
-    /// Gets a runtime upstream by ID.
+    /// Gets a dynamic upstream by ID.
     #[must_use]
-    pub fn get(&self, id: &str) -> Option<RuntimeUpstreamConfig> {
-        let upstreams = self.runtime_upstreams.read();
+    pub fn get(&self, id: &str) -> Option<DynamicUpstreamConfig> {
+        let upstreams = self.dynamic_upstreams.read();
         upstreams.get(id).cloned()
     }
 
-    /// Lists all runtime upstreams.
+    /// Lists all dynamic upstreams.
     #[must_use]
-    pub fn list_all(&self) -> Vec<RuntimeUpstreamConfig> {
-        let upstreams = self.runtime_upstreams.read();
+    pub fn list_all(&self) -> Vec<DynamicUpstreamConfig> {
+        let upstreams = self.dynamic_upstreams.read();
         upstreams.values().cloned().collect()
     }
 
@@ -241,16 +241,16 @@ impl RuntimeUpstreamRegistry {
         if self.is_config_upstream(name) {
             Some(UpstreamSource::Config)
         } else {
-            let upstreams = self.runtime_upstreams.read();
+            let upstreams = self.dynamic_upstreams.read();
             if upstreams.values().any(|u| u.name == name) {
-                Some(UpstreamSource::Runtime)
+                Some(UpstreamSource::Dynamic)
             } else {
                 None
             }
         }
     }
 
-    /// Loads runtime upstreams from disk.
+    /// Loads dynamic upstreams from disk.
     ///
     /// # Errors
     ///
@@ -261,15 +261,15 @@ impl RuntimeUpstreamRegistry {
         };
 
         if !path.exists() {
-            debug!("no runtime upstreams file found, starting fresh");
+            debug!("no dynamic upstreams file found, starting fresh");
             return Ok(());
         }
 
         let contents = fs::read_to_string(path)?;
-        let configs: Vec<RuntimeUpstreamConfig> = serde_json::from_str(&contents)
+        let configs: Vec<DynamicUpstreamConfig> = serde_json::from_str(&contents)
             .map_err(|e| std::io::Error::new(std::io::ErrorKind::InvalidData, e))?;
 
-        let mut upstreams = self.runtime_upstreams.write();
+        let mut upstreams = self.dynamic_upstreams.write();
         upstreams.clear();
         for config in configs {
             upstreams.insert(config.id.clone(), config);
@@ -278,13 +278,13 @@ impl RuntimeUpstreamRegistry {
         info!(
             count = upstreams.len(),
             path = %path.display(),
-            "loaded runtime upstreams from disk"
+            "loaded dynamic upstreams from disk"
         );
 
         Ok(())
     }
 
-    /// Saves runtime upstreams to disk.
+    /// Saves dynamic upstreams to disk.
     ///
     /// # Errors
     ///
@@ -294,8 +294,8 @@ impl RuntimeUpstreamRegistry {
             return Ok(()); // No storage path configured
         };
 
-        let upstreams = self.runtime_upstreams.read();
-        let configs: Vec<RuntimeUpstreamConfig> = upstreams.values().cloned().collect();
+        let upstreams = self.dynamic_upstreams.read();
+        let configs: Vec<DynamicUpstreamConfig> = upstreams.values().cloned().collect();
         drop(upstreams);
 
         // Create parent directory if needed
@@ -311,16 +311,16 @@ impl RuntimeUpstreamRegistry {
         debug!(
             count = configs.len(),
             path = %path.display(),
-            "saved runtime upstreams to disk"
+            "saved dynamic upstreams to disk"
         );
 
         Ok(())
     }
 }
 
-/// Updates to apply to a runtime upstream.
+/// Updates to apply to a dynamic upstream.
 #[derive(Debug, Clone, Default)]
-pub struct RuntimeUpstreamUpdate {
+pub struct DynamicUpstreamUpdate {
     pub name: Option<String>,
     pub url: Option<String>,
     pub ws_url: Option<Option<String>>,
@@ -333,8 +333,8 @@ mod tests {
     use super::*;
     use tempfile::TempDir;
 
-    fn create_test_config(id: &str, name: &str) -> RuntimeUpstreamConfig {
-        RuntimeUpstreamConfig {
+    fn create_test_config(id: &str, name: &str) -> DynamicUpstreamConfig {
+        DynamicUpstreamConfig {
             id: id.to_string(),
             name: name.to_string(),
             url: format!("https://{name}.example.com"),
@@ -349,8 +349,8 @@ mod tests {
     }
 
     #[test]
-    fn test_add_runtime_upstream() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+    fn test_add_dynamic_upstream() {
+        let registry = DynamicUpstreamRegistry::new(None);
         let config = create_test_config("1", "test-upstream");
 
         let result = registry.add(&config);
@@ -364,7 +364,7 @@ mod tests {
 
     #[test]
     fn test_duplicate_name_rejection() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
 
         let config1 = create_test_config("1", "test-upstream");
         let config2 = create_test_config("2", "test-upstream");
@@ -375,7 +375,7 @@ mod tests {
 
     #[test]
     fn test_config_upstream_conflict() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
         registry.initialize_config_upstreams(vec!["config-upstream".to_string()]);
 
         let config = create_test_config("1", "config-upstream");
@@ -387,12 +387,12 @@ mod tests {
 
     #[test]
     fn test_update_upstream() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
         let config = create_test_config("1", "test-upstream");
 
         registry.add(&config).unwrap();
 
-        let updates = RuntimeUpstreamUpdate {
+        let updates = DynamicUpstreamUpdate {
             name: Some("updated-name".to_string()),
             weight: Some(200),
             ..Default::default()
@@ -408,7 +408,7 @@ mod tests {
 
     #[test]
     fn test_remove_upstream() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
         let config = create_test_config("1", "test-upstream");
 
         registry.add(&config).unwrap();
@@ -421,7 +421,7 @@ mod tests {
 
     #[test]
     fn test_list_all() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
 
         let config1 = create_test_config("1", "upstream-1");
         let config2 = create_test_config("2", "upstream-2");
@@ -435,32 +435,32 @@ mod tests {
 
     #[test]
     fn test_get_source() {
-        let registry = RuntimeUpstreamRegistry::new(None);
+        let registry = DynamicUpstreamRegistry::new(None);
         registry.initialize_config_upstreams(vec!["config-upstream".to_string()]);
 
-        let config = create_test_config("1", "runtime-upstream");
+        let config = create_test_config("1", "dynamic-upstream");
         registry.add(&config).unwrap();
 
         assert_eq!(registry.get_source("config-upstream"), Some(UpstreamSource::Config));
-        assert_eq!(registry.get_source("runtime-upstream"), Some(UpstreamSource::Runtime));
+        assert_eq!(registry.get_source("dynamic-upstream"), Some(UpstreamSource::Dynamic));
         assert_eq!(registry.get_source("non-existent"), None);
     }
 
     #[test]
     fn test_persistence() {
         let temp_dir = TempDir::new().unwrap();
-        let storage_path = temp_dir.path().join("runtime_upstreams.json");
+        let storage_path = temp_dir.path().join("dynamic_upstreams.json");
 
         // Create registry and add upstreams
         {
-            let registry = RuntimeUpstreamRegistry::new(Some(storage_path.clone()));
+            let registry = DynamicUpstreamRegistry::new(Some(storage_path.clone()));
             let config = create_test_config("1", "test-upstream");
             registry.add(&config).unwrap();
         }
 
         // Load from disk in new registry
         {
-            let registry = RuntimeUpstreamRegistry::new(Some(storage_path));
+            let registry = DynamicUpstreamRegistry::new(Some(storage_path));
             registry.load_from_disk().unwrap();
 
             let upstreams = registry.list_all();
diff --git a/crates/prism-core/src/upstream/endpoint.rs b/crates/prism-core/src/upstream/endpoint.rs
index a1b0a95..a9e181e 100644
--- a/crates/prism-core/src/upstream/endpoint.rs
+++ b/crates/prism-core/src/upstream/endpoint.rs
@@ -1,7 +1,7 @@
 use std::{
     collections::VecDeque,
     sync::{
-        atomic::{AtomicBool, Ordering},
+        atomic::{AtomicBool, AtomicU64, Ordering},
         Arc,
     },
     time::Duration,
@@ -38,6 +38,10 @@ pub struct HealthHistoryEntry {
 
 const HEALTH_HISTORY_SIZE: usize = 100;
 
+/// Time-to-live for cached health status in milliseconds.
+/// Health checks that occur within this window will use the cached value.
+const HEALTH_CACHE_TTL_MS: u64 = 100;
+
 /// Represents an upstream RPC endpoint with health tracking, circuit breaker protection,
 /// and WebSocket support for real-time chain updates.
 ///
@@ -57,6 +61,10 @@ pub struct UpstreamEndpoint {
     health_check_result: Arc<RwLock<watch::Sender<Option<HealthCheckResult>>>>,
     health_check_receiver: watch::Receiver<Option<HealthCheckResult>>,
     health_history: Arc<RwLock<VecDeque<HealthHistoryEntry>>>,
+    /// Cached health status to avoid lock contention on every request
+    cached_is_healthy: AtomicBool,
+    /// Timestamp (ms since epoch) when cached health was last updated
+    health_cache_time: AtomicU64,
 }
 
 impl UpstreamEndpoint {
@@ -85,6 +93,8 @@ impl UpstreamEndpoint {
             health_check_result: Arc::new(RwLock::new(health_check_tx)),
             health_check_receiver: health_check_rx,
             health_history: Arc::new(RwLock::new(VecDeque::with_capacity(HEALTH_HISTORY_SIZE))),
+            cached_is_healthy: AtomicBool::new(false),
+            health_cache_time: AtomicU64::new(0),
         }
     }
 
@@ -227,13 +237,31 @@ impl UpstreamEndpoint {
 
     /// Checks if this upstream is currently healthy and available for requests.
     ///
+    /// Uses a 100ms cache to reduce lock contention on high-throughput workloads.
     /// Returns `true` only if both the health status is good and the circuit breaker
     /// is closed (allowing requests through).
     pub async fn is_healthy(&self) -> bool {
+        // Fast path: check cache first (lock-free)
+        let cache_time = self.health_cache_time.load(Ordering::Relaxed);
+        let now_ms = std::time::SystemTime::now()
+            .duration_since(std::time::UNIX_EPOCH)
+            .map(|d| d.as_millis() as u64)
+            .unwrap_or(0);
+
+        if now_ms.saturating_sub(cache_time) < HEALTH_CACHE_TTL_MS {
+            return self.cached_is_healthy.load(Ordering::Relaxed);
+        }
+
+        // Slow path: acquire locks and update cache
         let health = self.health.read().await;
         let circuit_breaker_allows = self.circuit_breaker.can_execute().await;
+        let is_healthy = health.is_healthy && circuit_breaker_allows;
+
+        // Update cache (race is benign - worst case is redundant computation)
+        self.cached_is_healthy.store(is_healthy, Ordering::Relaxed);
+        self.health_cache_time.store(now_ms, Ordering::Relaxed);
 
-        health.is_healthy && circuit_breaker_allows
+        is_healthy
     }
 
     /// Returns the current health status including response time and error count.
@@ -241,6 +269,13 @@ impl UpstreamEndpoint {
         self.health.read().await.clone()
     }
 
+    /// Invalidates the health cache, forcing the next `is_healthy()` call to recompute.
+    /// This is useful after external state changes (like circuit breaker state changes)
+    /// that affect health but don't go through `update_health()`.
+    pub fn invalidate_health_cache(&self) {
+        self.health_cache_time.store(0, Ordering::Relaxed);
+    }
+
     /// Returns a reference to the upstream configuration.
     #[must_use]
     pub fn config(&self) -> &UpstreamConfig {
@@ -567,6 +602,9 @@ impl UpstreamEndpoint {
                 );
             }
         }
+
+        // Invalidate health cache so next is_healthy() call will recompute
+        self.health_cache_time.store(0, Ordering::Relaxed);
     }
 }
 
@@ -610,11 +648,13 @@ mod tests {
 
         endpoint.circuit_breaker().on_failure().await;
         endpoint.circuit_breaker().on_failure().await;
+        endpoint.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
 
         assert_eq!(endpoint.get_circuit_breaker_state().await, CircuitBreakerState::Open);
         assert!(!endpoint.is_healthy().await);
 
         endpoint.circuit_breaker().on_success().await;
+        endpoint.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
         assert_eq!(endpoint.get_circuit_breaker_state().await, CircuitBreakerState::Closed);
         assert!(endpoint.is_healthy().await);
     }
@@ -636,15 +676,18 @@ mod tests {
         assert_eq!(endpoint.get_circuit_breaker_failure_count().await, 0);
 
         endpoint.circuit_breaker().on_failure().await;
+        endpoint.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
         assert_eq!(endpoint.get_circuit_breaker_failure_count().await, 1);
         assert!(endpoint.is_healthy().await);
 
         endpoint.circuit_breaker().on_failure().await;
+        endpoint.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
         assert_eq!(endpoint.get_circuit_breaker_failure_count().await, 2);
         assert_eq!(endpoint.get_circuit_breaker_state().await, CircuitBreakerState::Open);
         assert!(!endpoint.is_healthy().await);
 
         endpoint.circuit_breaker().on_success().await;
+        endpoint.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
         assert_eq!(endpoint.get_circuit_breaker_state().await, CircuitBreakerState::Closed);
         assert!(endpoint.is_healthy().await);
         assert_eq!(endpoint.get_circuit_breaker_failure_count().await, 0);
diff --git a/crates/prism-core/src/upstream/load_balancer.rs b/crates/prism-core/src/upstream/load_balancer.rs
index a4641e4..d7f3e46 100644
--- a/crates/prism-core/src/upstream/load_balancer.rs
+++ b/crates/prism-core/src/upstream/load_balancer.rs
@@ -1004,6 +1004,7 @@ mod tests {
 
         failing_upstream.circuit_breaker().on_failure().await;
         failing_upstream.circuit_breaker().on_failure().await;
+        failing_upstream.invalidate_health_cache(); // Cache invalidation needed after direct circuit breaker manipulation
 
         let healthy_upstreams = balancer.get_healthy_upstreams().await;
         assert_eq!(healthy_upstreams.len(), 1);
diff --git a/crates/prism-core/src/upstream/manager.rs b/crates/prism-core/src/upstream/manager.rs
index 395a4d4..ddc4647 100644
--- a/crates/prism-core/src/upstream/manager.rs
+++ b/crates/prism-core/src/upstream/manager.rs
@@ -1,8 +1,8 @@
 use super::{
     circuit_breaker::CircuitBreakerState,
     consensus::{ConsensusConfig, ConsensusEngine},
+    dynamic_registry::{DynamicUpstreamConfig, DynamicUpstreamRegistry, DynamicUpstreamUpdate},
     router::{RoutingContext, SmartRouter},
-    runtime_registry::{RuntimeUpstreamConfig, RuntimeUpstreamRegistry, RuntimeUpstreamUpdate},
     scoring::{ScoringConfig, ScoringEngine, UpstreamScore},
     HedgeConfig, HedgeExecutor, LoadBalancer, UpstreamEndpoint, UpstreamError,
 };
@@ -51,7 +51,7 @@ pub struct UpstreamManager {
     consensus_engine: Arc<ConsensusEngine>,
     routing_context: Arc<RoutingContext>,
     router: Arc<SmartRouter>,
-    runtime_registry: Arc<RuntimeUpstreamRegistry>,
+    dynamic_registry: Arc<DynamicUpstreamRegistry>,
 }
 
 /// Configuration for the `UpstreamManager`.
@@ -124,7 +124,7 @@ impl UpstreamManager {
         consensus_engine: Arc<ConsensusEngine>,
         routing_context: Arc<RoutingContext>,
         router: Arc<SmartRouter>,
-        runtime_registry: Arc<RuntimeUpstreamRegistry>,
+        dynamic_registry: Arc<DynamicUpstreamRegistry>,
     ) -> Self {
         Self {
             load_balancer,
@@ -135,7 +135,7 @@ impl UpstreamManager {
             consensus_engine,
             routing_context,
             router,
-            runtime_registry,
+            dynamic_registry,
         }
     }
 
@@ -475,33 +475,33 @@ impl UpstreamManager {
         self.consensus_engine.is_enabled().await
     }
 
-    /// Returns a reference to the runtime upstream registry.
+    /// Returns a reference to the dynamic upstream registry.
     #[must_use]
-    pub fn get_runtime_registry(&self) -> Arc<RuntimeUpstreamRegistry> {
-        self.runtime_registry.clone()
+    pub fn get_dynamic_registry(&self) -> Arc<DynamicUpstreamRegistry> {
+        self.dynamic_registry.clone()
     }
 
-    /// Adds a runtime upstream and registers it in the runtime registry.
+    /// Adds a dynamic upstream and registers it in the dynamic registry.
     ///
     /// # Errors
     ///
     /// Returns an error if:
     /// - The upstream name conflicts with an existing upstream
     /// - Validation fails (invalid URL, weight out of range, etc.)
-    /// - Registration in the runtime registry fails
-    pub fn add_runtime_upstream(
+    /// - Registration in the dynamic registry fails
+    pub fn add_dynamic_upstream(
         &self,
         request: CreateUpstreamRequest,
-    ) -> Result<RuntimeUpstreamConfig, UpstreamError> {
+    ) -> Result<DynamicUpstreamConfig, UpstreamError> {
         // Validate request
         validate_upstream_request(&request)?;
 
         // Generate ID
         let id = uuid::Uuid::new_v4().to_string();
 
-        // Create runtime upstream config
+        // Create dynamic upstream config
         let now = chrono::Utc::now().to_rfc3339();
-        let runtime_config = RuntimeUpstreamConfig {
+        let dynamic_config = DynamicUpstreamConfig {
             id: id.clone(),
             name: request.name.clone(),
             url: request.url.clone(),
@@ -514,9 +514,9 @@ impl UpstreamManager {
             updated_at: now,
         };
 
-        // Register in runtime registry
-        self.runtime_registry
-            .add(&runtime_config)
+        // Register in dynamic registry
+        self.dynamic_registry
+            .add(&dynamic_config)
             .map_err(UpstreamError::InvalidRequest)?;
 
         // Create UpstreamConfig for load balancer
@@ -535,11 +535,11 @@ impl UpstreamManager {
         // Add to load balancer
         self.add_upstream(upstream_config);
 
-        info!(id = %id, name = %runtime_config.name, "added runtime upstream");
-        Ok(runtime_config)
+        info!(id = %id, name = %dynamic_config.name, "added dynamic upstream");
+        Ok(dynamic_config)
     }
 
-    /// Updates a runtime upstream.
+    /// Updates a dynamic upstream.
     ///
     /// # Errors
     ///
@@ -548,21 +548,21 @@ impl UpstreamManager {
     /// - The upstream ID doesn't exist
     /// - Validation fails
     /// - Update fails
-    pub fn update_runtime_upstream(
+    pub fn update_dynamic_upstream(
         &self,
         id: &str,
         updates: &UpdateUpstreamRequest,
-    ) -> Result<RuntimeUpstreamConfig, UpstreamError> {
+    ) -> Result<DynamicUpstreamConfig, UpstreamError> {
         // Get current config
-        let current = self.runtime_registry.get(id).ok_or_else(|| {
-            UpstreamError::InvalidRequest(format!("Runtime upstream '{id}' not found"))
+        let current = self.dynamic_registry.get(id).ok_or_else(|| {
+            UpstreamError::InvalidRequest(format!("Dynamic upstream '{id}' not found"))
         })?;
 
         // Validate updates
         validate_upstream_updates(updates)?;
 
         // Build update struct for registry
-        let mut registry_update = RuntimeUpstreamUpdate::default();
+        let mut registry_update = DynamicUpstreamUpdate::default();
 
         if let Some(ref name) = updates.name {
             registry_update.name = Some(name.clone());
@@ -578,12 +578,12 @@ impl UpstreamManager {
         }
 
         // Update in registry
-        self.runtime_registry
+        self.dynamic_registry
             .update(id, registry_update)
             .map_err(UpstreamError::InvalidRequest)?;
 
         // Get updated config
-        let updated_config = self.runtime_registry.get(id).ok_or_else(|| {
+        let updated_config = self.dynamic_registry.get(id).ok_or_else(|| {
             UpstreamError::InvalidRequest("Failed to retrieve updated config".to_string())
         })?;
 
@@ -624,47 +624,47 @@ impl UpstreamManager {
             self.add_upstream(upstream_config);
         }
 
-        info!(id = %id, name = %updated_config.name, "updated runtime upstream");
+        info!(id = %id, name = %updated_config.name, "updated dynamic upstream");
         Ok(updated_config)
     }
 
-    /// Removes a runtime upstream.
+    /// Removes a dynamic upstream.
     ///
     /// # Errors
     ///
     /// Returns an error if:
     /// - The upstream is a config-based upstream (cannot remove)
     /// - The upstream ID doesn't exist
-    pub fn remove_runtime_upstream(&self, id: &str) -> Result<(), UpstreamError> {
+    pub fn remove_dynamic_upstream(&self, id: &str) -> Result<(), UpstreamError> {
         // Get the config to check it exists and get the name
-        let config = self.runtime_registry.get(id).ok_or_else(|| {
-            UpstreamError::InvalidRequest(format!("Runtime upstream '{id}' not found"))
+        let config = self.dynamic_registry.get(id).ok_or_else(|| {
+            UpstreamError::InvalidRequest(format!("Dynamic upstream '{id}' not found"))
         })?;
 
         // Remove from registry
-        self.runtime_registry.remove(id).map_err(UpstreamError::InvalidRequest)?;
+        self.dynamic_registry.remove(id).map_err(UpstreamError::InvalidRequest)?;
 
         // Remove from load balancer
         self.remove_upstream(&config.name);
 
-        info!(id = %id, name = %config.name, "removed runtime upstream");
+        info!(id = %id, name = %config.name, "removed dynamic upstream");
         Ok(())
     }
 
-    /// Gets a runtime upstream by ID.
+    /// Gets a dynamic upstream by ID.
     #[must_use]
-    pub fn get_runtime_upstream(&self, id: &str) -> Option<RuntimeUpstreamConfig> {
-        self.runtime_registry.get(id)
+    pub fn get_dynamic_upstream(&self, id: &str) -> Option<DynamicUpstreamConfig> {
+        self.dynamic_registry.get(id)
     }
 
-    /// Lists all runtime upstreams.
+    /// Lists all dynamic upstreams.
     #[must_use]
-    pub fn list_runtime_upstreams(&self) -> Vec<RuntimeUpstreamConfig> {
-        self.runtime_registry.list_all()
+    pub fn list_dynamic_upstreams(&self) -> Vec<DynamicUpstreamConfig> {
+        self.dynamic_registry.list_all()
     }
 }
 
-/// Request to create a new runtime upstream.
+/// Request to create a new dynamic upstream.
 #[derive(Debug, Clone)]
 pub struct CreateUpstreamRequest {
     pub name: String,
@@ -675,7 +675,7 @@ pub struct CreateUpstreamRequest {
     pub timeout_seconds: u64,
 }
 
-/// Request to update a runtime upstream.
+/// Request to update a dynamic upstream.
 #[derive(Debug, Clone, Default)]
 pub struct UpdateUpstreamRequest {
     pub name: Option<String>,
diff --git a/crates/prism-core/src/upstream/mod.rs b/crates/prism-core/src/upstream/mod.rs
index bf7dbe5..6f8205b 100644
--- a/crates/prism-core/src/upstream/mod.rs
+++ b/crates/prism-core/src/upstream/mod.rs
@@ -54,6 +54,7 @@
 pub mod builder;
 pub mod circuit_breaker;
 pub mod consensus;
+pub mod dynamic_registry;
 pub mod endpoint;
 pub mod errors;
 pub mod health;
@@ -64,7 +65,6 @@ pub mod load_balancer;
 pub mod manager;
 pub mod misbehavior;
 pub mod router;
-pub mod runtime_registry;
 pub mod scoring;
 pub mod websocket;
 
@@ -74,6 +74,9 @@ pub use consensus::{
     ConsensusConfig, ConsensusEngine, ConsensusMetadata, ConsensusResult, DisputeBehavior,
     FailureBehavior, LowParticipantsBehavior, ResponseGroup, SelectionMethod,
 };
+pub use dynamic_registry::{
+    DynamicUpstreamConfig, DynamicUpstreamRegistry, DynamicUpstreamUpdate, UpstreamSource,
+};
 pub use endpoint::UpstreamEndpoint;
 pub use errors::{RpcErrorCategory, UpstreamError};
 pub use hedging::{HedgeConfig, HedgeExecutor};
@@ -86,8 +89,5 @@ pub use manager::{
 };
 pub use misbehavior::{MisbehaviorConfig, MisbehaviorStats, MisbehaviorTracker};
 pub use router::{RoutingContext, SmartRouter};
-pub use runtime_registry::{
-    RuntimeUpstreamConfig, RuntimeUpstreamRegistry, RuntimeUpstreamUpdate, UpstreamSource,
-};
 pub use scoring::{ScoringConfig, ScoringEngine, ScoringWeights, UpstreamMetrics, UpstreamScore};
 pub use websocket::{WebSocketFailureTracker, WebSocketHandler};
diff --git a/crates/prism-core/src/upstream/websocket.rs b/crates/prism-core/src/upstream/websocket.rs
index 1b659cb..6a23545 100644
--- a/crates/prism-core/src/upstream/websocket.rs
+++ b/crates/prism-core/src/upstream/websocket.rs
@@ -648,6 +648,13 @@ impl WebSocketHandler {
             "params": [with_hex_u64(block_number, std::string::ToString::to_string), true]
         });
 
+        tracing::debug!(
+            block_number = block_number,
+            upstream = upstream_name,
+            request = ?block_req,
+            "sending eth_getBlockByNumber with fullTransactions=true"
+        );
+
         let block_response = Self::send_json_request(
             http_client,
             url,
@@ -663,6 +670,43 @@ impl WebSocketHandler {
             return Err("no result in block response".to_string());
         };
 
+        // Log transaction field structure to debug caching issues
+        if let Some(tx_field) = block_data.get("transactions") {
+            let tx_type = if tx_field.is_array() {
+                let arr = tx_field.as_array().unwrap();
+                if arr.is_empty() {
+                    "empty_array".to_string()
+                } else if let Some(first) = arr.first() {
+                    if first.is_string() {
+                        format!("array_of_hashes (count: {})", arr.len())
+                    } else if first.is_object() {
+                        format!("array_of_objects (count: {})", arr.len())
+                    } else {
+                        format!("array_of_unknown (count: {})", arr.len())
+                    }
+                } else {
+                    "empty_array".to_string()
+                }
+            } else if tx_field.is_null() {
+                "null".to_string()
+            } else {
+                format!("unexpected_type: {:?}", tx_field)
+            };
+
+            tracing::info!(
+                block_number = block_number,
+                upstream = upstream_name,
+                transactions_type = tx_type,
+                "received block response with transactions field"
+            );
+        } else {
+            tracing::warn!(
+                block_number = block_number,
+                upstream = upstream_name,
+                "block response has no transactions field at all"
+            );
+        }
+
         Self::cache_block_data(block_number, upstream_name, cache_manager, block_data).await;
 
         Self::fetch_and_cache_receipts_for_block(
@@ -762,18 +806,88 @@ impl WebSocketHandler {
             tracing::debug!(block_number = block_number, upstream = upstream_name, "cached body");
         }
 
-        if let Some(transactions) = block_data.get("transactions").and_then(|v| v.as_array()) {
-            for tx_json in transactions {
-                if let Some(tx) = json_transaction_to_transaction_record(tx_json) {
-                    cache_manager.transaction_cache.insert_transaction(tx).await;
+        // Check if transactions field exists
+        match block_data.get("transactions") {
+            None => {
+                tracing::warn!(
+                    block_number = block_number,
+                    upstream = upstream_name,
+                    "block data has no 'transactions' field"
+                );
+            }
+            Some(tx_value) => {
+                // Check if it's an array
+                match tx_value.as_array() {
+                    None => {
+                        tracing::warn!(
+                            block_number = block_number,
+                            upstream = upstream_name,
+                            tx_value_type = ?tx_value,
+                            "transactions field is not an array (possibly null or transaction hashes)"
+                        );
+                    }
+                    Some(transactions) => {
+                        if transactions.is_empty() {
+                            tracing::debug!(
+                                block_number = block_number,
+                                upstream = upstream_name,
+                                "block has no transactions (empty block)"
+                            );
+                        } else {
+                            let mut cached_count = 0;
+                            let mut failed_count = 0;
+
+                            // Check first transaction to see if we got hashes or objects
+                            if let Some(first_tx) = transactions.first() {
+                                if first_tx.is_string() {
+                                    tracing::error!(
+                                        block_number = block_number,
+                                        upstream = upstream_name,
+                                        transaction_count = transactions.len(),
+                                        first_tx = ?first_tx,
+                                        "BUG: eth_getBlockByNumber returned transaction HASHES instead of full objects! \
+                                         This means fullTransactions=true parameter is not working correctly."
+                                    );
+                                    return;
+                                }
+                            }
+
+                            for tx_json in transactions {
+                                if let Some(tx) = json_transaction_to_transaction_record(tx_json) {
+                                    cache_manager.transaction_cache.insert_transaction(tx).await;
+                                    cached_count += 1;
+                                } else {
+                                    failed_count += 1;
+                                    tracing::debug!(
+                                        block_number = block_number,
+                                        upstream = upstream_name,
+                                        tx_json = ?tx_json,
+                                        "failed to convert transaction to record"
+                                    );
+                                }
+                            }
+
+                            if failed_count > 0 {
+                                tracing::warn!(
+                                    block_number = block_number,
+                                    upstream = upstream_name,
+                                    total_count = transactions.len(),
+                                    cached_count = cached_count,
+                                    failed_count = failed_count,
+                                    "some transactions failed to convert (check for EIP-1559+ support or missing fields)"
+                                );
+                            } else if cached_count > 0 {
+                                tracing::debug!(
+                                    block_number = block_number,
+                                    upstream = upstream_name,
+                                    transaction_count = cached_count,
+                                    "cached transactions"
+                                );
+                            }
+                        }
+                    }
                 }
             }
-            tracing::debug!(
-                block_number = block_number,
-                upstream = upstream_name,
-                transaction_count = transactions.len(),
-                "cached transactions"
-            );
         }
     }
 
